# 2021.12.07
#etc/2021.12.07

---
```
Scikit-Learn
- numpy와 scipy 기반위에서 구축된 라이브러리
- 데이터 마이닝과 머신러닝을 위한 하이레벨 라이브러리
	- 지도 학습, 비지도 학습에 관련된 다양한 메서드를 제공
	- 딥러닝이나 강화학습은 다루지않음( 딥러닝이나 강화학습은 텐서플로우)
	- 텐서플로우는 상대적으로 로우레벨 라이브러리에 가까움
		- 텐서플로우는 신경망이나 딥러닝 위주의 데이터 계산, 연산을 위한 라라이브러리
- 다양한 머신러닝용 파이썬 라이브러리
- 심플하고 일관성 있는 API, 유용한 온라인 문서, 풍부한 예제
- 머신러닝을 위한 쉽고 효율적인 개발 라이브러리 제공
- 많은 사람들이 사용하며 다양한 환경에서 검증된 라이브러리

주요 모듈...

Estimator ApI(학습 모델)의 사용
- 적절한 estimator 클래스를 임포트
- 모델의 하이퍼 파라미터 선택
- 데이터를 특징 배열과 대상 벡터로 배치
- fit() 메서드를 호출해 학습
- 모델을 새 데이터(테스트 데이터)에 대해서 적용

sklearn.datasets

k-nn
k 최근접 이웃 분류
- 입력 데이터 포인트와 가장 가까운 k개의 훈련 데이터포인트를 선택
- k개의 데이터포인트중 가장 많은 클래스가 예측 결과

X_y : X 특정데이터, y 근사치 데이터

SVM(Support Vector Machine)
-딥러닝 이전에 좋은 성능으로 주목받던 분류모델
-분류를 위해 가장 좋은 결정 경게를 학습하는 기법
	- 결정 경계: 데이터를 가장 잘 분리하는 경계
	- 서포트 벡터: 결정 결계와 가장 가까운 점들
	- 마진: 결정 경계와 서포트 베거틔 거리 *2
	-> svm은 이러한 마진을 최대화하는 분류 모델 

svm은 입력데이터가 정규화 되어야 성능이 좋음
preprocessing

커널기법: linear, polynomial, rbf

decision tree
의사 결정규칙을 트리로 나타내 전체 데이터를 소집단으로 분류하거나 예측
- 전체 데이터를 잘분리(순도높게) 할수 잇는 특징을 차례대로 찾아서 전체 트리 구성
- 불순도를 속성들에 대해 반복적으로 계산
	- 지니 계수: 확률적 분산
	- 엔트로피 계수: 불확실성 정도

Naive Bayes
bayes 정리를 적용한 확률적 분류 알고리즘
P(H|E) = P(E|H)P(H)/P(E)

P(H): 사전 확률 -> 아무런 근거없이 H가 일어날 통계적 확률 -> 사전지식, 배경지식이라고함
P(H|E): 사후확률 -> 어떤 evidence 실마리/특징이 있는 사건이 발행한후에 H가 발생할것으로 믿는 확률 -> 추가 정보로 인해 H사건에 대한 믿음에 변화가 일어남
P(H|E) : 가능도라함. 우도라고도함
- 어떤 사건이 어떤 특징/징후를 가질 확률/가능성
P(E): 전체사건에서 E의 특징을 가지는 사건의 확률

앙상블(Ensemble)
여러 학습 모델을 혼합하여 학습하는 방식(voting, bagging, boosting)
```